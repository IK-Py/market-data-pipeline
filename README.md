# End-to-End Market Data Warehouse (AWS ELT Pipeline)

A production-grade Data Engineering pipeline designed to automate the extraction, loading, and transformation (ELT) of financial market data. This project demonstrates a serverless architecture capable of handling batch data processing with built-in quality assurance.

## ğŸš€ Project Overview
This pipeline automates the journey of financial data from a third-party API (Alpha Vantage) into a structured Amazon Redshift Data Warehouse. It focuses on scalability, idempotency, and data integrity.



## ğŸ›  Tech Stack
* **Infrastructure:** AWS (Lambda, S3, Glue, Redshift, EventBridge)
* **Languages:** Python 3.9+, SQL (Redshift/PostgreSQL dialect)
* **Libraries:** `boto3`, `redshift-connector`, `requests`, `python-dotenv`
* **Orchestration:** EventBridge (Scheduling) & AWS Glue (ETL Jobs)

## ğŸ“ Repository Structure
```text
.
â”œâ”€â”€ src/                    # Python logic
â”‚   â”œâ”€â”€ extract_lambda.py   # API extraction and S3 partitioning
â”‚   â”œâ”€â”€ glue_transform.py   # Data movement and SQL orchestration
â”‚   â””â”€â”€ quality_checks.py   # Post-load data validation
â”œâ”€â”€ sql/                    # Database logic
â”‚   â”œâ”€â”€ ddl_schema.sql      # Staging and Fact table definitions
â”‚   â””â”€â”€ transformations.sql # Data cleaning and Upsert logic
â”œâ”€â”€ docs/                   # Detailed documentation
â”‚   â”œâ”€â”€ architecture.md     # System design & config keys
â”‚   â””â”€â”€ data_dictionary.md  # Schema and field definitions
â”œâ”€â”€ .gitignore              # Git safety
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project overview
